{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This is the Jupyter notebook template for Assignment 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we load the needed modules (feel free to add more as needed)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%matplotlib inline\n",
    "# Allows viewing figures inline in the notebook\n",
    "import numpy as np\n",
    "# Numpy is a library for numerical computation\n",
    "import matplotlib.pyplot as plt\n",
    "# Matplotlib is a plotting library"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Template for Exercise 4: Gradient descent for the Netflix Problem\r\n",
    "Below, you will first load and view the data, and then fill in:\r\n",
    "* The template function **netflix_gradient**, which computes the gradient of E with respect to a and b\r\n",
    "* The gradient descent template function **netflix**, where you only need to fill in:\r\n",
    "    * the update step (initialization and convergence criteria are already taken care of)\r\n",
    "    * the computation of the gradient magnitude\r\n",
    "    * you may also want to play with the learning rate\r\n",
    "* Note: You may want to implement additional functions for debugging purposes\r\n",
    "\r\n",
    "Start out by loading and viewing the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load and view the incomplete matrix\n",
    "M = np.loadtxt('data/netflix_matrix.txt')\n",
    "# Uncomment if you want to view it\n",
    "#print(M)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def netflix_gradient(M, A, B):\n",
    "    # This function is meant to compute the gradient of E with respect to A and B\n",
    "    # Given: * the (6 x 10) numpy array M, whose 0 inputs you want to replace by predictions, \n",
    "    #          and whose nonzero inputs you want to preserve\n",
    "    #        * two variable numpy arrays A (of size 6 x 2) and B (of size 2 x 10), \n",
    "    #          over which you want to optimize to reconstruct the matrix M as well as possible as a product A*B.\n",
    "    # Return: The gradients grad_A and grad_B of the cost function E from the exercise, \n",
    "    #         with respect to a and b, respectively. They should have the same shape as a and b.\n",
    "    I = M.copy()\n",
    "\n",
    "    for i in range(6) :\n",
    "        for j in range(10) : \n",
    "            if M[i][j]!= 0 :\n",
    "                I[i][j]=1\n",
    "    \n",
    "    grad_A = np.array([[0.0 for _ in range (2)] for _ in range(6)])\n",
    "    grad_B = np.array([[0.0 for _ in range (10)] for _ in range(2)])\n",
    "    \n",
    "    for j in range(10) :\n",
    "        for i in range (6) :\n",
    "            for m in range(2) :\n",
    "                grad_A[i][m] += ( 2*(I[i][j] * (-M[i][j]*B[m][j] + A[i][0]*B[0][j]*B[m][j] + A[i][1]*B[1][j]*B[m][j])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(6) :\n",
    "        for m in range(2) :\n",
    "            for j in range(10) :\n",
    "                grad_B[m][j] += ( 2*(I[i][j] * (-M[i][j]*A[i][m] + (A[i][0]*A[i][m]*B[0][j]  + A[i][1]*A[i][m]*B[1][j]))) )\n",
    "    \n",
    "    return grad_A, grad_B"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "people,movies = M.shape\n",
    "A = np.random.randn(people,2)\n",
    "B = np.random.randn(2,movies)\n",
    "M = np.loadtxt('data/netflix_matrix.txt')\n",
    "\n",
    "netflix_gradient(M, A, B)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[  6.58214476,   7.05470948],\n",
       "        [ 51.41011298,  10.86608718],\n",
       "        [ 18.47536829,   2.11554703],\n",
       "        [ 40.70997782, -37.8844176 ],\n",
       "        [-11.52492287,  -0.16289661],\n",
       "        [  1.5719143 , -56.57883361]]),\n",
       " array([[-40.00786889, -31.4931686 ,  -9.62996094,   5.57404517,\n",
       "          -3.76316248, -35.74130616, -57.84776049, -40.8446648 ,\n",
       "          15.15112134, -30.63325691],\n",
       "        [-20.36778163, -23.60052669, -52.47919776, -23.0275985 ,\n",
       "         -16.56895741,  -5.94704374, -33.9555731 ,  -7.39991805,\n",
       "         -10.48685027, -26.68399881]]))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def netflix(M):\n",
    "    # A template function for performing gradient descent over A and B to minimize E\n",
    "    # Input: The matrix M to be approximated\n",
    "    people,movies = M.shape\n",
    "    \n",
    "    # Initialize at random\n",
    "    np.random.seed(1) # Fixed seed for reproducibility; please don't change\n",
    "    A = np.random.randn(people,2)\n",
    "    B = np.random.randn(2,movies)\n",
    "    \n",
    "    # Set learning rate (you may want to play with this)\n",
    "    learningrate = 0.00001\n",
    "    \n",
    "    # Setting parameters for convergence check\n",
    "    num_iter = 1                   # This is the variable that will keep track of the number of iterations\n",
    "    convergence = 0                # This is the variable that will keep track of whether we have converged\n",
    "    max_iter = 100000               # We stop the algorithm after this many iterations\n",
    "    tolerance = 0.01               # We conclude convergence when the magnitude of the gradient\n",
    "                                   # is less than the tolerance\n",
    "    \n",
    "    while convergence == 0:\n",
    "        ####################### MISSING PART ############## \n",
    "        # Compute gradient and take a step in the direction it dictates\n",
    "        grad_A, grad_B = netflix_gradient(M, A, B)\n",
    "        \n",
    "        A = A - np.dot(grad_A, learningrate)\n",
    "        B = B - np.dot(grad_B, learningrate)\n",
    "        \n",
    "        ####################### MISSING PART ##############        \n",
    "        # Check for convergence -- you need to fill in the computation of the norm of the gradient at the current location\n",
    "        num_iter = num_iter + 1      \n",
    "        cur_grad_norm = np.sqrt(np.linalg.norm(grad_A)**2 + np.linalg.norm(grad_B)**2)\n",
    "        \n",
    "        if cur_grad_norm < tolerance:\n",
    "            convergence = 1\n",
    "            print('converged')\n",
    "        elif num_iter > max_iter:\n",
    "            convergence = 1 \n",
    "            print('reached maximum nr of iterations')\n",
    "    return A, B"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, run your code to return your resulting A, B and A*B, and compare it with M"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\n",
    "M = np.loadtxt('data/netflix_matrix.txt')\n",
    "\n",
    "A, B = netflix(M)\n",
    "\n",
    "M_pred = np.matmul(A,B)\n",
    "\n",
    "\n",
    "for i in range(6) :\n",
    "    for j in range(10):\n",
    "        M_pred[i][j] = round(M_pred[i][j])\n",
    "\n",
    "M_fill = M.copy()\n",
    "\n",
    "for i in range(6) :\n",
    "    for j in range(10):\n",
    "        if M_fill[i][j] ==0 :\n",
    "            M_fill[i][j]= M_pred[i][j]\n",
    "\n",
    "print (\"ORIGINAL M : \\n\", M)\n",
    "print (\"PREDiCTED M : \\n\", M_pred)\n",
    "\n",
    "\n",
    "\n",
    "print (\"M FILLED HOLES : \\n\", M_fill)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "reached maximum nr of iterations\n",
      "ORIGINAL M : \n",
      " [[ 7.  8.  9.  0.  0.  1.  4.  2.  3.  9.]\n",
      " [ 0.  0. 10.  9. 10.  2.  3.  0.  0.  5.]\n",
      " [10.  9.  0.  8.  0.  0.  0.  2.  1.  3.]\n",
      " [ 1.  0.  2.  0.  0.  9.  8.  9.  0.  0.]\n",
      " [ 0.  1.  1.  0.  2.  0.  9.  0.  7.  0.]\n",
      " [ 2.  1.  0.  0.  1. 10.  0.  9.  0.  8.]]\n",
      "PREDiCTED M : \n",
      " [[ 8.  8. 10. 10. 10.  2.  4.  4.  3.  6.]\n",
      " [ 8.  8. 10.  9. 10.  1.  3.  3.  3.  6.]\n",
      " [ 9.  9. 11.  8. 12. -2.  1.  1.  1.  4.]\n",
      " [ 2.  1.  2.  9.  2.  9.  8.  9.  6.  9.]\n",
      " [ 1.  1.  1. 10.  2. 11.  9. 10.  7. 10.]\n",
      " [ 1.  1.  1.  9.  1. 10.  8.  9.  6.  9.]]\n",
      "M FILLED HOLES : \n",
      " [[ 7.  8.  9. 10. 10.  1.  4.  2.  3.  9.]\n",
      " [ 8.  8. 10.  9. 10.  2.  3.  3.  3.  5.]\n",
      " [10.  9. 11.  8. 12. -2.  1.  2.  1.  3.]\n",
      " [ 1.  1.  2.  9.  2.  9.  8.  9.  6.  9.]\n",
      " [ 1.  1.  1. 10.  2. 11.  9. 10.  7. 10.]\n",
      " [ 2.  1.  1.  9.  1. 10.  8.  9.  6.  8.]]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}